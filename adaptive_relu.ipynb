{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic libraries\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Import PyTorch\n",
    "import torch # import main library\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn # import modules\n",
    "from torch.autograd import Function # import Function to create custom activations\n",
    "from torch.nn.parameter import Parameter # import Parameter to create custom activations with learnable parameters\n",
    "from torch import optim # import optimizers for demonstrations\n",
    "import torch.nn.functional as F # import torch functions\n",
    "from torchvision import datasets, transforms # import transformations to use for demo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Define a transform\n",
    "  transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "  # Download and load the training data for Fashion MNIST\n",
    "  trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "  trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# helper function to train a model\n",
    "def train_model(model, trainloader, epochs=5):\n",
    "    '''\n",
    "    Function trains the model and prints out the training log.\n",
    "    INPUT:\n",
    "        model - initialized PyTorch model ready for training.\n",
    "        trainloader - PyTorch dataloader for training data.\n",
    "    '''\n",
    "    #setup training\n",
    "\n",
    "    #define loss function\n",
    "    criterion = nn.NLLLoss()\n",
    "    #define learning rate\n",
    "    learning_rate = 0.003\n",
    "    #initialize optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    #run training and print out the loss to make sure that we are actually fitting to the training set\n",
    "    print('Training the model. Make sure that loss decreases after each epoch.\\n')\n",
    "    loss_records = []\n",
    "    for e in range(epochs):\n",
    "        running_loss = 0\n",
    "        for images, labels in trainloader:\n",
    "            images = images.view(images.shape[0], -1)\n",
    "            log_ps = model(images)\n",
    "            loss = criterion(log_ps, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        else:\n",
    "            # print out the loss to make sure it is decreasing\n",
    "            print(f\"Training loss: {running_loss}\")\n",
    "            \n",
    "        loss_records.append(running_loss)\n",
    "            \n",
    "    return loss_records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# simply define a silu function\n",
    "def silu(input):\n",
    "    '''\n",
    "    Applies the Sigmoid Linear Unit (SiLU) function element-wise:\n",
    "        SiLU(x) = x * sigmoid(x)\n",
    "    '''\n",
    "    return input * torch.sigmoid(input) # use torch.sigmoid to make sure that we created the most efficient implemetation based on builtin PyTorch functions\n",
    "\n",
    "# create a class wrapper from PyTorch nn.Module, so\n",
    "# the function now can be easily used in models\n",
    "class SiLU(nn.Module):\n",
    "    '''\n",
    "    Applies the Sigmoid Linear Unit (SiLU) function element-wise:\n",
    "        SiLU(x) = x * sigmoid(x)\n",
    "    Shape:\n",
    "        - Input: (N, *) where * means, any number of additional\n",
    "          dimensions\n",
    "        - Output: (N, *), same shape as the input\n",
    "    References:\n",
    "        -  Related paper:\n",
    "        https://arxiv.org/pdf/1606.08415.pdf\n",
    "    Examples:\n",
    "        >>> m = silu()\n",
    "        >>> input = torch.randn(2)\n",
    "        >>> output = m(input)\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Init method.\n",
    "        '''\n",
    "        super().__init__() # init the base class\n",
    "\n",
    "    def forward(self, input):\n",
    "        '''\n",
    "        Forward pass of the function.\n",
    "        '''\n",
    "        return silu(input) # simply apply already implemented SiLU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model. Make sure that loss decreases after each epoch.\n",
      "\n",
      "Training loss: 471.4954441636801\n",
      "Training loss: 341.5519505441189\n",
      "Training loss: 309.5684223920107\n",
      "Training loss: 291.05133636295795\n",
      "Training loss: 274.3823933750391\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# use SiLU with model created with Sequential\n",
    "\n",
    "# initialize activation function\n",
    "activation_function = SiLU()\n",
    "\n",
    "# Initialize the model using nn.Sequential\n",
    "model = nn.Sequential(OrderedDict([\n",
    "                      ('fc1', nn.Linear(784, 256)),\n",
    "                      ('activation1', activation_function), # use SiLU\n",
    "                      ('fc2', nn.Linear(256, 128)),\n",
    "                      ('bn2', nn.BatchNorm1d(num_features=128)),\n",
    "                      ('activation2', activation_function), # use SiLU\n",
    "                      ('dropout', nn.Dropout(0.3)),\n",
    "                      ('fc3', nn.Linear(128, 64)),\n",
    "                      ('bn3', nn.BatchNorm1d(num_features=64)),\n",
    "                      ('activation3', activation_function), # use SiLU\n",
    "                      ('logits', nn.Linear(64, 10)),\n",
    "                      ('logsoftmax', nn.LogSoftmax(dim=1))]))\n",
    "\n",
    "# Run training\n",
    "train_model(model, trainloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class soft_exponential(nn.Module):\n",
    "    '''\n",
    "    Implementation of soft exponential activation.\n",
    "    Shape:\n",
    "        - Input: (N, *) where * means, any number of additional\n",
    "          dimensions\n",
    "        - Output: (N, *), same shape as the input\n",
    "    Parameters:\n",
    "        - alpha - trainable parameter\n",
    "    References:\n",
    "        - See related paper:\n",
    "        https://arxiv.org/pdf/1602.01321.pdf\n",
    "    Examples:\n",
    "        >>> a1 = soft_exponential(256)\n",
    "        >>> x = torch.randn(256)\n",
    "        >>> x = a1(x)\n",
    "    '''\n",
    "    def __init__(self, in_features, alpha = None):\n",
    "        '''\n",
    "        Initialization.\n",
    "        INPUT:\n",
    "            - in_features: shape of the input\n",
    "            - aplha: trainable parameter\n",
    "            aplha is initialized with zero value by default\n",
    "        '''\n",
    "        super(soft_exponential,self).__init__()\n",
    "        self.in_features = in_features\n",
    "\n",
    "        # initialize alpha\n",
    "        if alpha == None:\n",
    "            self.alpha = Parameter(torch.tensor(0.0)) # create a tensor out of alpha\n",
    "        else:\n",
    "            self.alpha = Parameter(torch.tensor(alpha)) # create a tensor out of alpha\n",
    "            \n",
    "        self.alpha.requiresGrad = True # set requiresGrad to true!\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Forward pass of the function.\n",
    "        Applies the function to the input elementwise.\n",
    "        '''\n",
    "        if (self.alpha == 0.0):\n",
    "            return x\n",
    "\n",
    "        if (self.alpha < 0.0):\n",
    "            return - torch.log(1 - self.alpha * (x + self.alpha)) / self.alpha\n",
    "\n",
    "        if (self.alpha > 0.0):\n",
    "            return (torch.exp(self.alpha * x) - 1)/ self.alpha + self.alpha\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class adaptive_relu(nn.Module):\n",
    "    def __init__(self, in_features, alpha=None):\n",
    "        super(adaptive_relu, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        \n",
    "        # initialize alpha\n",
    "        if alpha == None:\n",
    "            self.alpha = Parameter(torch.tensor(1.0)) # create a tensor out of alpha\n",
    "        else:\n",
    "            self.alpha = Parameter(torch.tensor(alpha)) # create a tensor out of alpha\n",
    "            \n",
    "        self.alpha.requiresGrad = True # set requiresGrad to true!        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.alpha * x.clamp(min=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model. Make sure that loss decreases after each epoch.\n",
      "\n",
      "Training loss: 482.4293819218874\n",
      "Training loss: 353.85101406276226\n",
      "Training loss: 321.3158094063401\n",
      "Training loss: 298.9575671479106\n",
      "Training loss: 287.5212336704135\n",
      "Training loss: 275.09870958328247\n",
      "Training loss: 264.70206071436405\n",
      "Training loss: 253.61597473919392\n",
      "Training loss: 246.37375557422638\n",
      "Training loss: 239.96719767153263\n",
      "Training loss: 235.48962399363518\n",
      "Training loss: 228.45708268508315\n",
      "Training loss: 223.462989423424\n",
      "Training loss: 219.65001448988914\n",
      "Training loss: 211.18569223210216\n",
      "Training the model. Make sure that loss decreases after each epoch.\n",
      "\n",
      "Training loss: 487.8173965513706\n",
      "Training loss: 356.13539984822273\n",
      "Training loss: 320.6074129343033\n",
      "Training loss: 298.69811776280403\n",
      "Training loss: 280.4814757928252\n",
      "Training loss: 265.92548632621765\n",
      "Training loss: 253.47678147256374\n",
      "Training loss: 244.5852853730321\n",
      "Training loss: 234.32841899245977\n",
      "Training loss: 224.80393916368484\n",
      "Training loss: 217.03164222091436\n",
      "Training loss: 208.45276134833694\n",
      "Training loss: 205.69670190289617\n",
      "Training loss: 198.98108962923288\n",
      "Training loss: 192.349473785609\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# create class for basic fully-connected deep neural network\n",
    "class Classifier_adaptive(nn.Module):\n",
    "    '''\n",
    "    Basic fully-connected network to test adaptive-relu activation.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # initialize layers\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "        self.a1 = adaptive_relu(256)\n",
    "        self.a2 = adaptive_relu(128)\n",
    "        self.a3 = adaptive_relu(64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # make sure the input tensor is flattened\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        # apply Soft Exponential unit\n",
    "        x = self.a1(self.fc1(x))\n",
    "        x = self.a2(self.fc2(x))\n",
    "        x = self.a3(self.fc3(x))\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "\n",
    "        return x\n",
    "    \n",
    "class Classifier(nn.Module):\n",
    "    '''\n",
    "    Basic fully-connected network to test adaptive-relu activation.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # initialize layers\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "        self.a1 = nn.ReLU(256)\n",
    "        self.a2 = nn.ReLU(128)\n",
    "        self.a3 = nn.ReLU(64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # make sure the input tensor is flattened\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        # apply Soft Exponential unit\n",
    "        x = self.a1(self.fc1(x))\n",
    "        x = self.a2(self.fc2(x))\n",
    "        x = self.a3(self.fc3(x))\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "\n",
    "        return x\n",
    "    \n",
    "model = Classifier()\n",
    "adaptive_model = Classifier_adaptive()\n",
    "\n",
    "loss = train_model(model, trainloader, epochs=15)\n",
    "adaptive_loss = train_model(adaptive_model, trainloader, epochs=15)\n",
    "\n",
    "plt.plot(loss, label='relu')\n",
    "plt.plot(adaptive_loss, label='adaptive relu')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('compare_relu.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model. Make sure that loss decreases after each epoch.\n",
      "\n",
      "Training loss: 557.7507739812136\n",
      "Training loss: 468.71403078734875\n",
      "Training loss: 446.58943282067776\n",
      "Training loss: 435.0755684673786\n",
      "Training loss: 427.3708694577217\n",
      "Training loss: 420.4459821432829\n",
      "Training loss: 418.87791903316975\n",
      "Training loss: 407.3105629235506\n",
      "Training loss: 414.770966604352\n",
      "Training loss: 400.8003673553467\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# create class for basic fully-connected deep neural network\n",
    "class ClassifierSExp(nn.Module):\n",
    "    '''\n",
    "    Basic fully-connected network to test Soft Exponential activation.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # initialize layers\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "        # initialize Soft Exponential activation\n",
    "        self.a1 = soft_exponential(256)\n",
    "        self.a2 = soft_exponential(128)\n",
    "        self.a3 = soft_exponential(64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # make sure the input tensor is flattened\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        # apply Soft Exponential unit\n",
    "        x = self.a1(self.fc1(x))\n",
    "        x = self.a2(self.fc2(x))\n",
    "        x = self.a3(self.fc3(x))\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "\n",
    "        return x\n",
    "    \n",
    "model = ClassifierSExp()\n",
    "train_model(model, trainloader, epochs=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
